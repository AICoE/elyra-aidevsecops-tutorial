# Deploy your model

There are different ways to deploy a model and different tools that can be used for that (e.g. Seldon, Tf-Serving, TensorRT), but for this tutorial we created a simple Flask application that can be easily deployed.

## Flask application

[Deploy Inference Application using Flask](./model-deployment/flask-application.md)

## KFServing

WIP

## TensorRT

WIP

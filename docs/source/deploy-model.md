# Deploy your model

There are different ways to deploy a model and there are different tools that can be used to do so (e.g. Seldon, Tf-Serving, TensorRT). But for this tutorial,  we created a simple Flask application that can be easily deployed.

## Flask application

[Deploy Inference Application using Flask](./model-deployment/flask-application.md)

## KFServing

WIP

## TensorRT

WIP

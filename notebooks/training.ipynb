{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022136,
     "end_time": "2021-02-03T13:27:33.986566",
     "exception": false,
     "start_time": "2021-02-03T13:27:33.964430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018835,
     "end_time": "2021-02-03T13:27:34.025541",
     "exception": false,
     "start_time": "2021-02-03T13:27:34.006706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 2.822829,
     "end_time": "2021-02-03T13:27:36.868108",
     "exception": false,
     "start_time": "2021-02-03T13:27:34.045279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020915,
     "end_time": "2021-02-03T13:27:36.912986",
     "exception": false,
     "start_time": "2021-02-03T13:27:36.892071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.0992,
     "end_time": "2021-02-03T13:27:37.033604",
     "exception": false,
     "start_time": "2021-02-03T13:27:36.934404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading elyra-aidevsecops-tutorial/data/raw/xdata.pkl into /opt/app-root/src/elyra-aidevsecops-tutorial/data/raw/xdata.pkl\n",
      "Downloading elyra-aidevsecops-tutorial/data/raw/ydata.pkl into /opt/app-root/src/elyra-aidevsecops-tutorial/data/raw/ydata.pkl\n",
      "Downloading elyra-aidevsecops-tutorial/data/raw/xtestdata.pkl into /opt/app-root/src/elyra-aidevsecops-tutorial/data/raw/xtestdata.pkl\n",
      "Downloading elyra-aidevsecops-tutorial/data/raw/ytestdata.pkl into /opt/app-root/src/elyra-aidevsecops-tutorial/data/raw/ytestdata.pkl\n"
     ]
    }
   ],
   "source": [
    "use_ceph = bool(int(os.getenv(\"TUTORIAL_USE_CEPH\", 1)))\n",
    "\n",
    "project_name = \"elyra-aidevsecops-tutorial\"\n",
    "\n",
    "# Path to data\n",
    "directory_path = Path.cwd().parents[0]\n",
    "raw_dataset_path = directory_path.joinpath(\n",
    "    str(os.environ.get(\"RAW_DATASET\", \"data/raw\"))\n",
    ")\n",
    "    \n",
    "if use_ceph:\n",
    "    # Download files from S3\n",
    "    s3_endpoint_url = os.getenv('ENDPOINT_URL', \"https://rgw-openshift-storage.apps.cnv.massopen.cloud/\")\n",
    "    s3_access_key = os.environ['AWS_ACCESS_KEY_ID']\n",
    "    s3_secret_key = os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "    s3_bucket = os.getenv('BUCKET_NAME', \"test-new-elyra-kfp-79f9251e-19c3-4d80-8b68-969e8495dd34\")\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client(service_name='s3',aws_access_key_id = s3_access_key,aws_secret_access_key = s3_secret_key, endpoint_url=s3_endpoint_url)\n",
    "\n",
    "\n",
    "    key = f\"{project_name}/data/raw/xdata.pkl\"\n",
    "    filename_path = str(f\"{raw_dataset_path}/xdata.pkl\")\n",
    "    print(f\"Downloading {key} into {filename_path}\")\n",
    "    s3.download_file(Bucket=s3_bucket, Key=key, Filename=filename_path)\n",
    "\n",
    "    key = f\"{project_name}/data/raw/ydata.pkl\"\n",
    "    filename_path = str(f\"{raw_dataset_path}/ydata.pkl\")\n",
    "    print(f\"Downloading {key} into {filename_path}\")\n",
    "    s3.download_file(Bucket=s3_bucket, Key=key, Filename=filename_path)\n",
    "\n",
    "    key = f\"{project_name}/data/raw/xtestdata.pkl\"\n",
    "    filename_path = str(f\"{raw_dataset_path}/xtestdata.pkl\")\n",
    "    print(f\"Downloading {key} into {filename_path}\")\n",
    "    s3.download_file(Bucket=s3_bucket, Key=key, Filename=filename_path)\n",
    "\n",
    "    key = f\"{project_name}/data/raw/ytestdata.pkl\"\n",
    "    filename_path = str(f\"{raw_dataset_path}/ytestdata.pkl\")\n",
    "    print(f\"Downloading {key} into {filename_path}\")\n",
    "    s3.download_file(Bucket=s3_bucket, Key=key, Filename=filename_path)\n",
    "\n",
    "\n",
    "\n",
    "pkl_file = open(f\"{raw_dataset_path}/xdata.pkl\", \"rb\")\n",
    "x_train = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "pkly_file = open(f\"{raw_dataset_path}/ydata.pkl\", \"rb\")\n",
    "y_train = pickle.load(pkly_file)\n",
    "pkly_file.close()\n",
    "\n",
    "pklxtest_file = open(f\"{raw_dataset_path}/xtestdata.pkl\", \"rb\")\n",
    "x_test = pickle.load(pklxtest_file)\n",
    "pklxtest_file.close()\n",
    "\n",
    "pklytest_file = open(f\"{raw_dataset_path}/ytestdata.pkl\", \"rb\")\n",
    "y_test = pickle.load(pklytest_file)\n",
    "pklytest_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021457,
     "end_time": "2021-02-03T13:27:37.078460",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.057003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.031268,
     "end_time": "2021-02-03T13:27:37.130774",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.099506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MNIST dataset parameters.\n",
    "num_classes = 10  # total classes (0-9 digits).\n",
    "\n",
    "# Training parameters.\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network parameters.\n",
    "conv1_filters = 32  # number of filters for 1st conv layer.\n",
    "conv2_filters = 64  # number of filters for 2nd conv layer.\n",
    "fc1_units = 1024  # number of neurons for 1st fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022993,
     "end_time": "2021-02-03T13:27:37.177673",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.154680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split Data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.20396,
     "end_time": "2021-02-03T13:27:37.405097",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.201137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Prepare MNIST data.\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"Number of images in x_train\", x_train.shape[0])\n",
    "print(\"Number of images in x_test\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022834,
     "end_time": "2021-02-03T13:27:37.477155",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.454321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.167411,
     "end_time": "2021-02-03T13:27:37.667600",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.500189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Creating a Sequential Model and adding the layers\n",
    "conv_net = Sequential()\n",
    "conv_net.add(\n",
    "    Conv2D(\n",
    "        conv1_filters,\n",
    "        kernel_size=(5, 5),\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        input_shape=input_shape,\n",
    "    )\n",
    ")\n",
    "conv_net.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "conv_net.add(\n",
    "    Conv2D(\n",
    "        conv2_filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
    "    )\n",
    ")\n",
    "conv_net.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "conv_net.add(Flatten())  # Flattening the 2D arrays for fully connected layers\n",
    "conv_net.add(Dense(fc1_units, activation=tf.nn.relu))\n",
    "conv_net.add(Dropout(0.5))\n",
    "conv_net.add(Dense(num_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022718,
     "end_time": "2021-02-03T13:27:37.714706",
     "exception": false,
     "start_time": "2021-02-03T13:27:37.691988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compiling and Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2021-02-03T13:27:37.738194",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1055/1875 [===============>..............] - ETA: 1:51 - loss: 0.3502 - accuracy: 0.8867"
     ]
    }
   ],
   "source": [
    "conv_net.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "conv_net.fit(x=x_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_net.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize predictions.\n",
    "\n",
    "n_images = 5\n",
    "\n",
    "# Display image and model prediction.\n",
    "for i in range(n_images):\n",
    "    plt.imshow(x_test[i], cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    prediction = conv_net.predict(x_test[i].reshape(1, 28, 28, 1))\n",
    "    print(\"Model prediction: %i\" % prediction.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to file\n",
    "# Fetch the Keras session and save the model\n",
    "\n",
    "time_version = f\"{datetime.now():%y%m%d%H%M%S}-{random.getrandbits(64):08x}\"\n",
    "\n",
    "# Path to data\n",
    "directory_path = Path.cwd().parents[0]\n",
    "trained_model_path = directory_path.joinpath(\n",
    "    str(os.environ.get(\"TRAINED_MODEL_PATH\", \"models\"))\n",
    ")\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    conv_net,\n",
    "    f\"{trained_model_path}/{time_version}/\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "/opt/app-root/src/elyra-aidevsecops-tutorial/notebooks/training.ipynb",
   "output_path": "/opt/app-root/src/elyra-aidevsecops-tutorial/notebooks/training.ipynb",
   "parameters": {},
   "start_time": "2021-02-03T13:27:32.988886",
   "version": "2.2.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
